{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection - Exploration and Analysis\n",
    "\n",
    "This notebook demonstrates how to use the Brain Tumor Detection system for data exploration, model training, and analysis.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Data Exploration](#data-exploration)\n",
    "3. [Model Training](#model-training)\n",
    "4. [Model Evaluation](#model-evaluation)\n",
    "5. [Predictions and Visualization](#predictions)\n",
    "6. [Grad-CAM Analysis](#gradcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom modules\n",
    "from models.brain_tumor_model import create_model\n",
    "from data.data_processor import DatasetManager, prepare_data\n",
    "from utils.evaluation import ModelEvaluator, GradCAM, plot_sample_predictions\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration {#data-exploration}\n",
    "\n",
    "Let's explore the dataset structure and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory path\n",
    "DATA_DIR = \"../data\"  # Update this path to your dataset\n",
    "\n",
    "# Check if data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"⚠️ Data directory {DATA_DIR} not found.\")\n",
    "    print(\"Please update the DATA_DIR variable with the correct path to your dataset.\")\n",
    "    print(\"\\nExpected structure:\")\n",
    "    print(\"data/\")\n",
    "    print(\"├── tumor/\")\n",
    "    print(\"│   ├── image1.jpg\")\n",
    "    print(\"│   ├── image2.jpg\")\n",
    "    print(\"│   └── ...\")\n",
    "    print(\"└── no_tumor/\")\n",
    "    print(\"    ├── image1.jpg\")\n",
    "    print(\"    ├── image2.jpg\")\n",
    "    print(\"    └── ...\")\n",
    "else:\n",
    "    print(f\"✅ Data directory found: {DATA_DIR}\")\n",
    "    \n",
    "    # List subdirectories (classes)\n",
    "    subdirs = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "    print(f\"Classes found: {subdirs}\")\n",
    "    \n",
    "    # Count images in each class\n",
    "    for subdir in subdirs:\n",
    "        class_path = os.path.join(DATA_DIR, subdir)\n",
    "        image_count = len([f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))])\n",
    "        print(f\"  {subdir}: {image_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset manager and load data\n",
    "if os.path.exists(DATA_DIR):\n",
    "    dataset_manager = DatasetManager(DATA_DIR, image_size=(224, 224), batch_size=32)\n",
    "    \n",
    "    # Load dataset\n",
    "    images, labels, class_names = dataset_manager.load_dataset_from_folder()\n",
    "    \n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Total images: {len(images)}\")\n",
    "    print(f\"Image shape: {images[0].shape}\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    \n",
    "    # Analyze dataset\n",
    "    dataset_manager.analyze_dataset(images, labels, class_names)\n",
    "else:\n",
    "    print(\"Skipping data exploration - please provide dataset path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training {#model-training}\n",
    "\n",
    "Create and train a brain tumor detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'base_model': 'resnet50',  # Options: 'resnet50', 'vgg16', 'efficientnetb0'\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'num_classes': 2,  # Binary classification: tumor/no tumor\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,  # Reduced for demo purposes\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "for key, value in MODEL_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_model(\n",
    "    base_model=MODEL_CONFIG['base_model'],\n",
    "    input_shape=MODEL_CONFIG['input_shape'],\n",
    "    num_classes=MODEL_CONFIG['num_classes']\n",
    ")\n",
    "\n",
    "# Compile with specified learning rate\n",
    "model.compile_model(learning_rate=MODEL_CONFIG['learning_rate'])\n",
    "\n",
    "print(\"✅ Model created and compiled successfully!\")\n",
    "print(\"\\nModel Summary:\")\n",
    "model.get_model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data generators (if dataset is available)\n",
    "if os.path.exists(DATA_DIR):\n",
    "    train_gen, val_gen, class_indices = prepare_data(\n",
    "        data_dir=DATA_DIR,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=MODEL_CONFIG['batch_size'],\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {train_gen.samples}\")\n",
    "    print(f\"Validation samples: {val_gen.samples}\")\n",
    "    print(f\"Class indices: {class_indices}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nStarting training...\")\n",
    "    history = model.train(\n",
    "        train_data=train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=MODEL_CONFIG['epochs']\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Training completed!\")\n",
    "else:\n",
    "    print(\"Skipping training - please provide dataset\")\n",
    "    history = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation {#model-evaluation}\n",
    "\n",
    "Evaluate the trained model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "if history is not None:\n",
    "    from utils.evaluation import ModelEvaluator\n",
    "    \n",
    "    # Create evaluator\n",
    "    evaluator = ModelEvaluator(model.model, list(class_indices.keys()))\n",
    "    \n",
    "    # Plot training history\n",
    "    evaluator.plot_training_history(history)\n",
    "else:\n",
    "    print(\"No training history available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation data\n",
    "if 'val_gen' in locals():\n",
    "    # Reset validation generator\n",
    "    val_gen.reset()\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = evaluator.evaluate_model(val_gen)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    evaluator.plot_confusion_matrix(results['y_true'], results['y_pred_classes'])\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    evaluator.plot_roc_curve(results['y_true'], results['y_pred'])\n",
    "else:\n",
    "    print(\"No validation data available for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions and Visualization {#predictions}\n",
    "\n",
    "Make predictions on sample images and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "if 'val_gen' in locals():\n",
    "    val_gen.reset()\n",
    "    plot_sample_predictions(model.model, val_gen, list(class_indices.keys()), num_samples=9)\n",
    "else:\n",
    "    print(\"No validation data available for sample predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on a single image (example)\n",
    "# Note: Replace 'path_to_image' with an actual image path\n",
    "\n",
    "def predict_single_image(model, image_path, class_names):\n",
    "    \"\"\"\n",
    "    Make prediction on a single image\n",
    "    \"\"\"\n",
    "    from data.data_processor import ImagePreprocessor\n",
    "    \n",
    "    preprocessor = ImagePreprocessor(target_size=(224, 224))\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = preprocessor.load_image(image_path)\n",
    "    \n",
    "    if image is not None:\n",
    "        # Make prediction\n",
    "        predicted_class, confidence = model.predict(image)\n",
    "        \n",
    "        print(f\"Image: {image_path}\")\n",
    "        print(f\"Predicted class: {class_names[predicted_class]}\")\n",
    "        print(f\"Confidence: {confidence:.3f}\")\n",
    "        \n",
    "        # Display image\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'Prediction: {class_names[predicted_class]} (Confidence: {confidence:.3f})')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    else:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None, None\n",
    "\n",
    "# Example usage (uncomment and provide actual image path)\n",
    "# image_path = \"path/to/your/image.jpg\"\n",
    "# if os.path.exists(image_path):\n",
    "#     pred_class, confidence = predict_single_image(model, image_path, list(class_indices.keys()))\n",
    "# else:\n",
    "#     print(\"Please provide a valid image path to test single image prediction\")\n",
    "\n",
    "print(\"Single image prediction function defined. Uncomment the example usage to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Grad-CAM Analysis {#gradcam}\n",
    "\n",
    "Generate Grad-CAM visualizations for model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Grad-CAM\n",
    "gradcam = GradCAM(model.model)\n",
    "\n",
    "print(\"✅ Grad-CAM initialized\")\n",
    "print(f\"Target layer: {gradcam.layer_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM for sample images\n",
    "if 'val_gen' in locals():\n",
    "    val_gen.reset()\n",
    "    \n",
    "    # Get a batch of validation images\n",
    "    batch_images, batch_labels = next(val_gen)\n",
    "    \n",
    "    # Generate Grad-CAM for first few images\n",
    "    num_samples = min(3, len(batch_images))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image = batch_images[i]\n",
    "        true_label = np.argmax(batch_labels[i])\n",
    "        \n",
    "        print(f\"\\nSample {i+1} - True label: {list(class_indices.keys())[true_label]}\")\n",
    "        \n",
    "        # Generate Grad-CAM visualization\n",
    "        gradcam.visualize_activation(image, figsize=(15, 5))\n",
    "else:\n",
    "    print(\"No validation data available for Grad-CAM analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model\n",
    "\n",
    "Save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "MODEL_DIR = \"../models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "model_name = f\"{MODEL_CONFIG['base_model']}_brain_tumor_model\"\n",
    "model_path = os.path.join(MODEL_DIR, f\"{model_name}.h5\")\n",
    "\n",
    "# Save model\n",
    "model.save_model(model_path)\n",
    "print(f\"✅ Model saved to: {model_path}\")\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    'model_name': MODEL_CONFIG['base_model'],\n",
    "    'input_shape': MODEL_CONFIG['input_shape'],\n",
    "    'num_classes': MODEL_CONFIG['num_classes'],\n",
    "    'image_size': 224,\n",
    "    'class_names': list(class_indices.keys()) if 'class_indices' in locals() else ['no_tumor', 'tumor']\n",
    "}\n",
    "\n",
    "import json\n",
    "config_path = os.path.join(MODEL_DIR, f\"{model_name}.json\")\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"✅ Configuration saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Exploration**: Loading and analyzing the brain tumor dataset\n",
    "2. **Model Training**: Creating and training a CNN model with transfer learning\n",
    "3. **Model Evaluation**: Assessing model performance with various metrics\n",
    "4. **Predictions**: Making predictions on individual images\n",
    "5. **Grad-CAM Analysis**: Generating interpretable visualizations\n",
    "6. **Model Saving**: Saving the trained model for deployment\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Web Application**: Use the trained model with the Streamlit web app (`streamlit run ../src/web_app.py`)\n",
    "- **API Server**: Deploy the model as a REST API (`python ../src/api_server.py`)\n",
    "- **Batch Processing**: Process multiple images (`python ../src/predict.py`)\n",
    "- **Fine-tuning**: Improve model performance with more data or fine-tuning\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "⚠️ **Medical Disclaimer**: This model is for research and educational purposes only. It should not be used for actual medical diagnosis. Always consult qualified healthcare professionals for medical decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}